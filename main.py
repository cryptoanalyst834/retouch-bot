import logging
import cv2
import numpy as np
from io import BytesIO
from PIL import Image
import os
import json
import requests
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ConversationHandler,
    ContextTypes,
    filters,
)
from dotenv import load_dotenv

load_dotenv()

logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

RETOUCH_WAITING_FOR_IMAGE = 1
RETOUCH_WAITING_FOR_OPTION = 2
ALLOWED_EXTENSIONS = ['.jpg', '.jpeg', '.heic']
MAX_FREE_RETOUCHES = 5

INSTRUCTIONS_TEXT = (
    "üìé –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ *—Ñ–∞–π–ª–æ–º*, –Ω–µ —Å–∂–∏–º–∞—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.\n\n"
    "üì± –¢–µ–ª–µ—Ñ–æ–Ω: –°–∫—Ä–µ–ø–∫–∞ ‚Üí –§–∞–π–ª ‚Üí –ì–∞–ª–µ—Ä–µ—è ‚Üí –û—Ç–ø—Ä–∞–≤–∏—Ç—å.\n"
    "üñ• –ü–ö: –°–∫—Ä–µ–ø–∫–∞ ‚Üí –í—ã–±—Ä–∞—Ç—å —Ñ–∞–π–ª ‚Üí –£–±—Ä–∞—Ç—å –≥–∞–ª–æ—á–∫—É '–°–∂–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ' ‚Üí –û—Ç–ø—Ä–∞–≤–∏—Ç—å.\n\n"
    "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç—ã JPG/JPEG/HEIC."
)

USERS_FILE = "users.json"
def load_users():
    if os.path.exists(USERS_FILE):
        with open(USERS_FILE, 'r') as f:
            return json.load(f)
    return {}

def save_users(data):
    with open(USERS_FILE, 'w') as f:
        json.dump(data, f)

users_data = load_users()

def get_user_data(user_id):
    user_id = str(user_id)
    if user_id not in users_data:
        users_data[user_id] = {"count": 0, "is_pro": False}
        save_users(users_data)
    return users_data[user_id]

def increment_user_count(user_id):
    user = get_user_data(user_id)
    user["count"] += 1
    save_users(users_data)

def user_has_access(user_id):
    user = get_user_data(user_id)
    return user["is_pro"] or user["count"] < MAX_FREE_RETOUCHES

def user_is_pro(user_id):
    return get_user_data(user_id).get("is_pro", False)

# === Image processing ===
def adjust_brightness_contrast(image, brightness=30, contrast=0):
    return cv2.convertScaleAbs(image, alpha=(contrast + 127) / 127, beta=brightness)

def remove_noise(image):
    return cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)

def correct_color_exposure(image):
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v_eq = cv2.equalizeHist(v)
    return cv2.cvtColor(cv2.merge((h, s, v_eq)), cv2.COLOR_HSV2BGR)

def skin_retouch(image):
    return cv2.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)

def enhance_sharpness(image):
    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])
    return cv2.filter2D(image, -1, kernel)

def full_process(image):
    image = adjust_brightness_contrast(image)
    image = skin_retouch(image)
    image = remove_noise(image)
    image = correct_color_exposure(image)
    image = enhance_sharpness(image)
    return image

def merge_images(img1, img2):
    im1 = Image.fromarray(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))
    im2 = Image.fromarray(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))
    new_im = Image.new('RGB', (im1.width + im2.width, max(im1.height, im2.height)))
    new_im.paste(im1, (0, 0))
    new_im.paste(im2, (im1.width, 0))
    output = BytesIO()
    new_im.save(output, format='JPEG')
    output.seek(0)
    return output

def neural_retouch_deepai(image_path: str) -> bytes:
    api_key = os.getenv("DEEPAI_API_KEY", "dd660eb7-a85c-490c-962b-eae835ff8c7c")
    try:
        response = requests.post(
            "https://api.deepai.org/api/torch-srgan",
            files={"image": open(image_path, "rb")},
            headers={"api-key": api_key}
        )
        result_url = response.json().get("output_url")
        if result_url:
            return requests.get(result_url).content
        else:
            raise ValueError("DeepAI API did not return output_url.")
    except Exception as e:
        raise RuntimeError(f"DeepAI API error: {e}")

# === Telegram Handlers ===
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç EasyRetouch ‚ú®\n–ò—Å–ø–æ–ª—å–∑—É–π /retouch, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–æ—Ç–æ.")

async def retouch_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(INSTRUCTIONS_TEXT, parse_mode="Markdown")
    return RETOUCH_WAITING_FOR_IMAGE

async def retouch_photo_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    if not user_has_access(user_id):
        keyboard = [[InlineKeyboardButton("–ü–æ–ª—É—á–∏—Ç—å Pro-–¥–æ—Å—Ç—É–ø üíé", url="https://t.me/your_payment_link")]]
        await update.message.reply_text(
            "–í—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ 5 –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π. –•–æ—Ç–∏—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å?", 
            reply_markup=InlineKeyboardMarkup(keyboard)
        )
        return ConversationHandler.END

    if update.message.document:
        file = await update.message.document.get_file()
        file_bytes = BytesIO()
        await file.download_to_memory(out=file_bytes)
        img = cv2.imdecode(np.frombuffer(file_bytes.getvalue(), dtype=np.uint8), cv2.IMREAD_COLOR)
        if img is None:
            await update.message.reply_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
            return ConversationHandler.END

        file_path = f"temp_{update.message.message_id}.jpg"
        cv2.imwrite(file_path, img)
        context.user_data["original_image"] = img
        context.user_data["file_path"] = file_path

        keyboard = [
            [InlineKeyboardButton("–õ–∞–π—Ç ‚ú®", callback_data="preset:light")],
            [InlineKeyboardButton("–ë—å—é—Ç–∏ üíÑ", callback_data="preset:beauty")],
            [InlineKeyboardButton("–ü—Ä–æ üéØ", callback_data="preset:pro")],
            [InlineKeyboardButton("–ù–µ–π—Ä–æ—Ä–µ—Ç—É—à—å üß†", callback_data="preset:neuro")],
        ]
        await update.message.reply_text("–í—ã–±–µ—Ä–∏ —Ä–µ–∂–∏–º —Ä–µ—Ç—É—à–∏:", reply_markup=InlineKeyboardMarkup(keyboard))
        return RETOUCH_WAITING_FOR_OPTION
    else:
        await update.message.reply_text(INSTRUCTIONS_TEXT)
        return ConversationHandler.END

async def retouch_option_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    user_id = query.from_user.id
    original = context.user_data.get("original_image")
    file_path = context.user_data.get("file_path")

    if original is None:
        await query.edit_message_text("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
        return ConversationHandler.END

    mode = query.data.split(":")[1]

    try:
        if mode == "light":
            result = correct_color_exposure(adjust_brightness_contrast(original))
        elif mode == "beauty":
            result = enhance_sharpness(remove_noise(skin_retouch(original)))
        elif mode == "pro":
            result = full_process(original)
        elif mode == "neuro":
            if not user_is_pro(user_id):
                await query.edit_message_text("–ù–µ–π—Ä–æ—Ä–µ—Ç—É—à—å –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è Pro-–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π üíé")
                return ConversationHandler.END
            processed_bytes = neural_retouch_deepai(file_path)
            result = cv2.imdecode(np.frombuffer(processed_bytes, dtype=np.uint8), cv2.IMREAD_COLOR)
        else:
            await query.edit_message_text("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä.")
            return ConversationHandler.END

        increment_user_count(user_id)
        merged = merge_images(original, result)
        await query.message.reply_photo(merged, caption=f"–†–µ–∂–∏–º: {mode.title()} ‚úÖ")
        await query.edit_message_text("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
        context.user_data.clear()
        if os.path.exists(file_path):
            os.remove(file_path)
        return ConversationHandler.END
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        await query.edit_message_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return ConversationHandler.END

async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ ‚ùå")
    return ConversationHandler.END

WEBHOOK_PATH = "/webhook"
WEBHOOK_URL = f"{os.getenv('WEBHOOK_BASE')}{WEBHOOK_PATH}"

def main():
    app = Application.builder().token(os.getenv("BOT_TOKEN")).build()

    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("retouch", retouch_start)],
        states={
            RETOUCH_WAITING_FOR_IMAGE: [MessageHandler(filters.Document.IMAGE | filters.PHOTO, retouch_photo_handler)],
            RETOUCH_WAITING_FOR_OPTION: [CallbackQueryHandler(retouch_option_handler, pattern="^preset:")],
        },
        fallbacks=[CommandHandler("cancel", cancel)],
    )

    app.add_handler(CommandHandler("start", start))
    app.add_handler(conv_handler)

    app.run_webhook(
        listen="0.0.0.0",
        port=int(os.getenv("PORT", 8000)),
        webhook_path=WEBHOOK_PATH,
        webhook_url=WEBHOOK_URL,
    )

if __name__ == '__main__':
    main()
